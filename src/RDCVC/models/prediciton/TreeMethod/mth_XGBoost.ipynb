{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for XGBoost model\n",
    "\n",
    "this notebook is used to find the best parameters for XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from utils.metrics import calculate_metrics, get_ccp_scoring\n",
    "from utils.datasets import load_and_split_data\n",
    "\n",
    "# ml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor, XGBRFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置显示中文字体\n",
    "\n",
    "from pylab import mpl\n",
    "\n",
    "mpl.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "# 设置正常显示符号\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 350\n",
      "测试集大小: 39\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/processed/rdc_data_cleaned.csv\"\n",
    "X_raw, Y_raw = load_and_split_data(data_path, test_size=0.1, is_split=False)\n",
    "\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_x.fit_transform(X_raw)\n",
    "y_scaled = scaler_y.fit_transform(Y_raw)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# 打印划分后的数据集大小\n",
    "print(\"训练集大小:\", len(x_train))\n",
    "print(\"测试集大小:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">              XGBoost_scaled              </span>\n",
       "┏━━━━━━━━━┯━━━━━━━━━┯━━━━━━━━━┯━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Feature </span>│<span style=\"font-weight: bold\"> MAE(Pa) </span>│<span style=\"font-weight: bold\">  MAPE   </span>│<span style=\"font-weight: bold\"> RMSE(Pa) </span>┃\n",
       "┠─────────┼─────────┼─────────┼──────────┨\n",
       "┃<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Airflow </span>│  84.48  │  8.17%  │  130.73  ┃\n",
       "┃<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Pres    </span>│  4.93   │ 159.30% │   7.54   ┃\n",
       "┗━━━━━━━━━┷━━━━━━━━━┷━━━━━━━━━┷━━━━━━━━━━┛\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m              XGBoost_scaled              \u001b[0m\n",
       "┏━━━━━━━━━┯━━━━━━━━━┯━━━━━━━━━┯━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mFeature\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mMAE(Pa)\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m MAPE  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mRMSE(Pa)\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┠─────────┼─────────┼─────────┼──────────┨\n",
       "┃\u001b[2m \u001b[0m\u001b[2mAirflow\u001b[0m\u001b[2m \u001b[0m│  84.48  │  8.17%  │  130.73  ┃\n",
       "┃\u001b[2m \u001b[0m\u001b[2mPres   \u001b[0m\u001b[2m \u001b[0m│  4.93   │ 159.30% │   7.54   ┃\n",
       "┗━━━━━━━━━┷━━━━━━━━━┷━━━━━━━━━┷━━━━━━━━━━┛\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost_scaled : {'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 9, 'n_estimators': 900}\n",
      "Best Score for XGBoost_scaled : -0.16530791756018723\n",
      "===============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"XGBoost_scaled\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    XGBRegressor(n_jobs=-1),\n",
    "    param_grid={\n",
    "        # ------------------------ Primary ----------------------- #\n",
    "        # Step size shrinkage used in boosting (Typical range: 0.01-0.3)\n",
    "        \"learning_rate\": [0.1],\n",
    "        # Maximum depth of each tree (Typical range: 3-10)\n",
    "        \"max_depth\": range(3, 10, 2),\n",
    "        # Number of boosting rounds (Typical range: 100-1000)\n",
    "        \"n_estimators\": range(100, 1000, 100),\n",
    "        # Minimum sum of instance weight needed in a child (Typical range: 1-10)\n",
    "        \"min_child_weight\": range(1, 10, 2),\n",
    "        # -------------------------------------------------------- #\n",
    "        # # Subsample ratio of the training instances (Typical range: 0.6-1.0)\n",
    "        # \"subsample\": [0.3, 0.5, 0.55],\n",
    "        # # Subsample ratio of columns when constructing each tree (Typical range: 0.6-1.0)\n",
    "        # \"colsample_bytree\": [1.0],\n",
    "        # # ----------------------- Secondary ---------------------- #\n",
    "        # # Minimum loss reduction required to make a further partition on a leaf node (Typical range: 0-0.5)\n",
    "        # \"gamma\": [0.3, 0.1, 0.5],\n",
    "        # # L1 regularization term on weights (Typical range: 0-0.1)\n",
    "        # \"reg_alpha\": [0.1],\n",
    "        # # L2 regularization term on weights (Typical range: 0-0.1)\n",
    "        # \"reg_lambda\": [0.07, 0.1],\n",
    "    },\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_search.fit(x_train, y_train)\n",
    "calculate_metrics(\n",
    "    scaler_y.inverse_transform(grid_search.best_estimator_.predict(x_test)),\n",
    "    scaler_y.inverse_transform(y_test),\n",
    "    print_metrics=True,\n",
    "    title=model_name,\n",
    ")\n",
    "print(\"Best Parameters for\", model_name, \":\", grid_search.best_params_)\n",
    "print(\"Best Score for\", model_name, \":\", grid_search.best_score_)\n",
    "print(\"=\" * 47 + \"\\n\" * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">             XGBoostRF_scaled              </span>\n",
       "┏━━━━━━━━━┯━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Feature </span>│<span style=\"font-weight: bold\"> MAE(Pa) </span>│<span style=\"font-weight: bold\">   MAPE   </span>│<span style=\"font-weight: bold\"> RMSE(Pa) </span>┃\n",
       "┠─────────┼─────────┼──────────┼──────────┨\n",
       "┃<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Airflow </span>│ 545.98  │ 125.37%  │  785.91  ┃\n",
       "┃<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Pres    </span>│  21.22  │ 1850.02% │  26.59   ┃\n",
       "┗━━━━━━━━━┷━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m             XGBoostRF_scaled              \u001b[0m\n",
       "┏━━━━━━━━━┯━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mFeature\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mMAE(Pa)\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m  MAPE  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mRMSE(Pa)\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┠─────────┼─────────┼──────────┼──────────┨\n",
       "┃\u001b[2m \u001b[0m\u001b[2mAirflow\u001b[0m\u001b[2m \u001b[0m│ 545.98  │ 125.37%  │  785.91  ┃\n",
       "┃\u001b[2m \u001b[0m\u001b[2mPres   \u001b[0m\u001b[2m \u001b[0m│  21.22  │ 1850.02% │  26.59   ┃\n",
       "┗━━━━━━━━━┷━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoostRF_scaled : {'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 100}\n",
      "Best Score for XGBoostRF_scaled : -0.8431200772536507\n",
      "===============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"XGBoostRF_scaled\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    XGBRFRegressor(n_jobs=-1),\n",
    "    param_grid={\n",
    "         # ------------------------ Primary ----------------------- #\n",
    "        # Step size shrinkage used in boosting (Typical range: 0.01-0.3)\n",
    "        \"learning_rate\": [0.1],\n",
    "        # Maximum depth of each tree (Typical range: 3-10)\n",
    "        \"max_depth\": range(3, 10, 2),\n",
    "        # Number of boosting rounds (Typical range: 100-1000)\n",
    "        \"n_estimators\": range(100, 1000, 100),\n",
    "        # Minimum sum of instance weight needed in a child (Typical range: 1-10)\n",
    "        \"min_child_weight\": range(1, 10, 2),\n",
    "        # -------------------------------------------------------- #\n",
    "        # # Subsample ratio of the training instances (Typical range: 0.6-1.0)\n",
    "        # \"subsample\": [0.3, 0.5, 0.55],\n",
    "        # # Subsample ratio of columns when constructing each tree (Typical range: 0.6-1.0)\n",
    "        # \"colsample_bytree\": [1.0],\n",
    "        # # ----------------------- Secondary ---------------------- #\n",
    "        # # Minimum loss reduction required to make a further partition on a leaf node (Typical range: 0-0.5)\n",
    "        # \"gamma\": [0.3, 0.1, 0.5],\n",
    "        # # L1 regularization term on weights (Typical range: 0-0.1)\n",
    "        # \"reg_alpha\": [0.1],\n",
    "        # # L2 regularization term on weights (Typical range: 0-0.1)\n",
    "        # \"reg_lambda\": [0.07, 0.1],\n",
    "    },\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_search.fit(x_train, y_train)\n",
    "calculate_metrics(\n",
    "    scaler_y.inverse_transform(grid_search.best_estimator_.predict(x_test)),\n",
    "    scaler_y.inverse_transform(y_test),\n",
    "    print_metrics=True,\n",
    "    title=model_name,\n",
    ")\n",
    "print(\"Best Parameters for\", model_name, \":\", grid_search.best_params_)\n",
    "print(\"Best Score for\", model_name, \":\", grid_search.best_score_)\n",
    "print(\"=\" * 47 + \"\\n\" * 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
